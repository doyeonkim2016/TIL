{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\doyeo\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\doyeo\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"TestApp\").getOrCreate()\n",
    "    print(\"Spark Session Created Successfully!\")\n",
    "    spark.stop()\n",
    "except Exception as e:\n",
    "    print(\"Error starting Spark:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialise Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"MovieLensAnalysis\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Load the ratings and movies CSV files into Dataframes\n",
    "ratings_df = spark.read.csv(r'C:\\Users\\doyeo\\Desktop\\SPARK\\Movie\\data\\rating.csv',header= True, inferSchema= True)\n",
    "movies_df = spark.read.csv(r'C:\\Users\\doyeo\\Desktop\\SPARK\\Movie\\data\\movie.csv',header= True, inferSchema= True)\n",
    "\n",
    "ratings_df.printSchema()\n",
    "movies_df.printSchema()\n",
    "\n",
    "ratings_df.show(5)\n",
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+----------+-----------+\n",
      "|movieId|               title|              genres|Avg_rating|Num_ratings|\n",
      "+-------+--------------------+--------------------+----------+-----------+\n",
      "| 120134|Doggiewoggiez! Po...|              Comedy|       5.0|          1|\n",
      "| 128093|Bo Burnham: Words...|              Comedy|       5.0|          1|\n",
      "| 112790|Going Down in LA-...|Comedy|Drama|Romance|       5.0|          1|\n",
      "| 121029|No Distance Left ...|         Documentary|       5.0|          1|\n",
      "| 129036|People of the Win...|         Documentary|       5.0|          1|\n",
      "| 114214|Mishen (Target) (...|        Drama|Sci-Fi|       5.0|          1|\n",
      "| 129034| Serving Life (2011)|         Documentary|       5.0|          1|\n",
      "|  40404| Al otro lado (2004)|               Drama|       5.0|          1|\n",
      "|  89133|Boys (Drenge) (1977)|               Drama|       5.0|          1|\n",
      "|  79866|Schmatta: Rags to...|         Documentary|       5.0|          1|\n",
      "+-------+--------------------+--------------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "# Group ratings by movieId to compute average rating and count of the ratings\n",
    "movie_ratings = ratings_df.groupBy(\"movieId\") \\\n",
    "                .agg(avg(\"rating\").alias(\"Avg_rating\"),count(\"rating\").alias(\"Num_ratings\"))\n",
    "\n",
    "#Join the aggregated ratings with movie details\n",
    "movie_details = movies_df.join(movie_ratings, on = \"movieId\", how=\"inner\")\n",
    "\n",
    "# View top 10 movies sorted by average rating\n",
    "movie_details.orderBy(movie_details.Avg_rating.desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+---------+\n",
      "|movieId|           title|    genre|\n",
      "+-------+----------------+---------+\n",
      "|      1|Toy Story (1995)|Adventure|\n",
      "|      1|Toy Story (1995)|Animation|\n",
      "|      1|Toy Story (1995)| Children|\n",
      "|      1|Toy Story (1995)|   Comedy|\n",
      "|      1|Toy Story (1995)|  Fantasy|\n",
      "+-------+----------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+------------------+----------+\n",
      "|             genre|  genre_avg_rating|num_movies|\n",
      "+------------------+------------------+----------+\n",
      "|         Film-Noir| 3.444150839287358|       322|\n",
      "|       Documentary| 3.436664522206703|      2391|\n",
      "|               War|3.3211370431752743|      1173|\n",
      "|              IMAX| 3.294670404912528|       195|\n",
      "|             Drama| 3.262038065956428|     13062|\n",
      "|           Romance|3.2057429873673713|      4029|\n",
      "|           Musical| 3.182132878495173|      1016|\n",
      "|         Animation| 3.177095212510683|      1015|\n",
      "|             Crime| 3.167141212246113|      2889|\n",
      "|           Mystery|3.1350738677584093|      1489|\n",
      "|           Fantasy| 3.093324230790383|      1398|\n",
      "|           Western| 3.075228316860353|       656|\n",
      "|            Comedy|3.0748694649959822|      8232|\n",
      "|         Adventure| 3.072407494188218|      2287|\n",
      "|          Thriller|3.0160951673247123|      4129|\n",
      "|            Action|2.9768762894084144|      3466|\n",
      "|          Children| 2.955607569754043|      1118|\n",
      "|            Sci-Fi| 2.890215234785487|      1720|\n",
      "|(no genres listed)|2.8037878787878787|       242|\n",
      "|            Horror|2.6967957652813705|      2590|\n",
      "+------------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode, avg, count\n",
    "\n",
    "# Assume movies_df has colums : movieId,title, genres,\n",
    "# Split the genres string by '|' and explode into separate row\n",
    "\n",
    "movies_exploded = movies_df.withColumn(\"genre\",explode(split(\"genres\",\"\\\\|\")))\n",
    "movies_exploded.select(\"movieId\",\"title\",\"genre\").show(5)\n",
    "\n",
    "# Aggregate ratings by movie\n",
    "# Aggregate ratings by movie\n",
    "movie_ratings = ratings_df.groupBy(\"movieId\").agg(\n",
    "    avg(\"rating\").alias(\"avg_rating\"),\n",
    "    count(\"rating\").alias(\"num_ratings\")\n",
    ")\n",
    "\n",
    "# Join movie details (with exploded genres) with the aggregated ratings\n",
    "movies_with_ratings = movies_exploded.join(movie_ratings, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "# Group by genre to compute overall average rating and the count of movies in each genre\n",
    "genre_analysis = movies_with_ratings.groupBy(\"genre\").agg(\n",
    "    avg(\"avg_rating\").alias(\"genre_avg_rating\"),\n",
    "    count(\"movieId\").alias(\"num_movies\")\n",
    ")\n",
    "\n",
    "genre_analysis.orderBy(\"genre_avg_rating\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------+\n",
      "|userId|num_ratings|        avg_rating|\n",
      "+------+-----------+------------------+\n",
      "|118205|       9254|3.2790685109141995|\n",
      "|  8405|       7515|3.2083166999334662|\n",
      "| 82418|       5646| 3.516914629826426|\n",
      "|121535|       5520|2.7931159420289857|\n",
      "|125794|       5491| 3.762975778546713|\n",
      "| 74142|       5447|1.5774738388103544|\n",
      "| 34576|       5356| 3.011669156086632|\n",
      "|131904|       5330| 3.248874296435272|\n",
      "| 83090|       5169|2.4049139098471657|\n",
      "| 59477|       4988|2.4550922213311948|\n",
      "+------+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate ratings by user\n",
    "user_analysis = ratings_df.groupBy(\"userId\").agg(\n",
    "    count(\"rating\").alias(\"num_ratings\"),\n",
    "    avg(\"rating\").alias(\"avg_rating\")\n",
    ").orderBy(\"num_ratings\", ascending=False)\n",
    "\n",
    "user_analysis.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------+\n",
      "|genre             |genre_avg_rating  |num_movies|\n",
      "+------------------+------------------+----------+\n",
      "|Film-Noir         |3.444150839287358 |322       |\n",
      "|Documentary       |3.436664522206703 |2391      |\n",
      "|War               |3.3211370431752743|1173      |\n",
      "|IMAX              |3.294670404912528 |195       |\n",
      "|Drama             |3.262038065956428 |13062     |\n",
      "|Romance           |3.2057429873673713|4029      |\n",
      "|Musical           |3.182132878495173 |1016      |\n",
      "|Animation         |3.177095212510683 |1015      |\n",
      "|Crime             |3.167141212246113 |2889      |\n",
      "|Mystery           |3.1350738677584093|1489      |\n",
      "|Fantasy           |3.093324230790383 |1398      |\n",
      "|Western           |3.075228316860353 |656       |\n",
      "|Comedy            |3.0748694649959822|8232      |\n",
      "|Adventure         |3.072407494188218 |2287      |\n",
      "|Thriller          |3.0160951673247123|4129      |\n",
      "|Action            |2.9768762894084144|3466      |\n",
      "|Children          |2.955607569754043 |1118      |\n",
      "|Sci-Fi            |2.890215234785487 |1720      |\n",
      "|(no genres listed)|2.8037878787878787|242       |\n",
      "|Horror            |2.6967957652813705|2590      |\n",
      "+------------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by genre to compute overall statistics\n",
    "genre_analysis = movies_with_ratings.groupBy(\"genre\").agg(\n",
    "    avg(\"avg_rating\").alias(\"genre_avg_rating\"),\n",
    "    count(\"movieId\").alias(\"num_movies\")\n",
    ").orderBy(\"genre_avg_rating\", ascending=False)\n",
    "\n",
    "# Show the results of the genre analysis\n",
    "genre_analysis.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data Sample:\n",
      "+-------+-----+---------+\n",
      "|movieId|tagId|relevance|\n",
      "+-------+-----+---------+\n",
      "|      1|    1|    0.025|\n",
      "|      1|    2|    0.025|\n",
      "|      1|    3|  0.05775|\n",
      "|      1|    4|  0.09675|\n",
      "|      1|    5|  0.14675|\n",
      "+-------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, when\n",
    "\n",
    "# Step 1: Extraction\n",
    "# -------------------\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL Pipeline Project\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read raw data from a CSV file (adjust the path as necessary)\n",
    "raw_data = spark.read.option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .csv(r\"C:\\Users\\doyeo\\Desktop\\SPARK\\Movie\\data\\genome_scores.csv\")\n",
    "\n",
    "# Preview the raw data\n",
    "print(\"Raw Data Sample:\")\n",
    "raw_data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Transformation\n",
    "# ----------------------\n",
    "# Data Cleaning:\n",
    "# - Remove records with null values in critical columns (e.g., 'id' or 'date')\n",
    "# - Filter out records with invalid or negative values in a numeric column (e.g., 'amount')\n",
    "cleaned_data = raw_data.filter(col(\"relevance\").isNotNull()) \\\n",
    "    .filter(col(\"relevance\") >= 0.03)\n",
    "\n",
    "# Data Conversion:\n",
    "# - Convert a string date column into a proper date type (adjust the date format as needed)\n",
    "cleaned_data = cleaned_data.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# - Cast numeric columns to proper data types if necessary\n",
    "cleaned_data = cleaned_data.withColumn(\"amount\", col(\"amount\").cast(\"double\"))\n",
    "\n",
    "# Additional Transformation:\n",
    "# - Rename columns for consistency and clarity\n",
    "transformed_data = cleaned_data.withColumnRenamed(\"old_name\", \"new_name\")\n",
    "# - Create new derived columns (example: flag large amounts)\n",
    "transformed_data = transformed_data.withColumn(\"large_amount_flag\", \n",
    "                                               when(col(\"amount\") > 1000, 1).otherwise(0))\n",
    "\n",
    "# Preview the transformed data\n",
    "print(\"Transformed Data Sample:\")\n",
    "transformed_data.show(5)\n",
    "\n",
    "# Step 3: Loading\n",
    "# ---------------\n",
    "# Write the transformed data to a target location in Parquet format\n",
    "output_path = \"output/cleaned_data.parquet\"\n",
    "transformed_data.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "print(f\"Data successfully written to {output_path}\")\n",
    "\n",
    "# Stop the Spark session once done\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
